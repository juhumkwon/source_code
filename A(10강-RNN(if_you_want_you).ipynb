import numpy as np
import tensorflow as tf

# 1. 데이터 준비
text = "if you want you"  # 학습할 텍스트
chars = sorted(set(text))  # 고유한 문자들
char_to_idx = {char: idx for idx, char in enumerate(chars)}  # 문자 -> 인덱스 변환
idx_to_char = {idx: char for idx, char in enumerate(chars)}  # 인덱스 -> 문자 변환

# 데이터 전처리 (입력 시퀀스와 출력 시퀀스 생성)
input_seq = [char_to_idx[char] for char in text[:-1]]  # 마지막 문자는 제외
output_seq = [char_to_idx[char] for char in text[1:]]  # 첫 번째 문자는 제외

# 입력과 출력을 (1, 시퀀스 길이) 형태로 변환
input_seq = np.array(input_seq).reshape(1, -1)
output_seq = np.array(output_seq).reshape(1, -1)

vocab_size = len(chars)  # 고유한 문자 개수
embedding_dim = 8        # 임베딩 차원 수
input_length = input_seq.shape[1]  # 입력 시퀀스 길이

# 2. RNN 모델 정의
model = tf.keras.Sequential([
    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=input_length),
    tf.keras.layers.SimpleRNN(64, return_sequences=True),
    tf.keras.layers.Dense(vocab_size, activation='softmax')
])

# 모델 컴파일
model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')

# 3. 학습
model.fit(input_seq, output_seq, epochs=100)

# 4. 예측
def generate_text(model, start_string, num_generate):
    # 입력 텍스트를 숫자로 변환
    input_eval = [char_to_idx[char] for char in start_string]
    input_eval = np.array(input_eval).reshape(1, -1)

    generated_text = start_string

    # 문자를 예측
    for _ in range(num_generate):
        predictions = model(input_eval)
        predicted_id = np.argmax(predictions[0, -1, :])

        # 예측한 문자를 기존 텍스트에 추가
        predicted_char = idx_to_char[predicted_id]
        generated_text += predicted_char
        print("generated_text=", generated_text)

        # 다음 입력 시퀀스를 생성 (문자 추가)
        input_eval = np.append(input_eval, [[predicted_id]], axis=1)

    return generated_text

# 5. 예시 텍스트 생성
print(generate_text(model, start_string="if you ", num_generate=10))
